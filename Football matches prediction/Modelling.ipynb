{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a87357-d033-4d61-a41e-f10dc76a346c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1) Reading file\n",
    "df = pd.read_csv(\"bundesliga_filtered.csv\")\n",
    "df = df[df[\"league\"] == \"Bundesliga\"].copy()\n",
    "\n",
    "#2) \"Strength feature engineering\"\n",
    "hist = df[df[\"season\"] < 2023]\n",
    "g = hist.groupby([\"team\", \"h_a\"])[\"scored\"].mean().reset_index()\n",
    "pivot = g.pivot(index=\"team\", columns=\"h_a\", values=\"scored\").reset_index()\n",
    "pivot.rename(columns={\"h\":\"home_strength\",\"a\":\"away_strength\"}, inplace=True)\n",
    "df = df.merge(pivot, on=\"team\", how=\"left\")\n",
    "df[\"home\"] = (df[\"h_a\"]==\"h\").astype(int)\n",
    "df[\"strength\"] = np.where(df[\"home\"]==1, df[\"home_strength\"], df[\"away_strength\"])\n",
    "\n",
    "#3) Data split ---\n",
    "train_data = df[df[\"season\"] < 2022].copy()   # 2013â€‘2021\n",
    "valid_data = df[df[\"season\"] == 2022].copy()  # 2022\n",
    "test_data  = df[df[\"season\"] == 2023].copy()  # 2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b0bd7-639f-4778-a678-1e2207d2075e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, brier_score_loss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# ------- features definition -------\n",
    "features_full = [\n",
    "    'xG','xGA','npxG','npxGA',\n",
    "    'deep','deep_allowed',\n",
    "    'ppda_coef','oppda_coef',\n",
    "    'home','strength'\n",
    "]\n",
    "features_reduced = ['xG','xGA','strength','ppda_coef','deep']\n",
    "\n",
    "target = 'result'\n",
    "\n",
    "# ------- encoding target variable -------\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_data[target])\n",
    "y_valid = le.transform(valid_data[target])\n",
    "y_test  = le.transform(test_data[target])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee657d1-2be8-4280-b834-b971e243a10b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- full and reduced features lists ---\n",
    "features_full = ['xG','xGA','npxG','npxGA','deep','deep_allowed',\n",
    "                 'ppda_coef','oppda_coef','home','strength']\n",
    "features_reduced = ['xG','xGA','strength','ppda_coef','deep']\n",
    "\n",
    "# --- features matrices ---\n",
    "X_train_full = train_data[features_full].fillna(0)\n",
    "X_valid_full = valid_data[features_full].fillna(0)\n",
    "X_test_full  = test_data[features_full].fillna(0)\n",
    "\n",
    "X_train_red = train_data[features_reduced].fillna(0)\n",
    "X_valid_red = valid_data[features_reduced].fillna(0)\n",
    "X_test_red  = test_data[features_reduced].fillna(0)\n",
    "\n",
    "# --- encoded target variable ---\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_data['result'])\n",
    "y_valid = le.transform(valid_data['result'])\n",
    "y_test  = le.transform(test_data['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c493c-29a5-4206-9545-24a6efa54c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model   Config  Accuracy  F1_macro     Brier\n",
      "0                   LDA     Full  0.635621  0.569343  0.163625\n",
      "1             SVC (rbf)  Reduced  0.632353  0.529288  0.165267\n",
      "2              AdaBoost  Reduced  0.630719  0.556078  0.209241\n",
      "3      GradientBoosting     Full  0.630719  0.555783  0.162378\n",
      "4                   LDA  Reduced  0.629085  0.556790  0.166356\n",
      "5         MLPClassifier  Reduced  0.629085  0.541441  0.165203\n",
      "6   Logistic Regression     Full  0.625817  0.527097  0.162869\n",
      "7              AdaBoost     Full  0.625817  0.550109  0.208955\n",
      "8          SVC (linear)  Reduced  0.625817  0.534995  0.165531\n",
      "9                   QDA  Reduced  0.624183  0.574631  0.177996\n",
      "10        MLPClassifier     Full  0.620915  0.538967  0.158160\n",
      "11  Logistic Regression  Reduced  0.620915  0.515837  0.165469\n",
      "12     GradientBoosting  Reduced  0.619281  0.530863  0.164689\n",
      "13             LightGBM     Full  0.619281  0.552855  0.172346\n",
      "14         SVC (linear)     Full  0.617647  0.527099  0.163243\n",
      "15        HistGradBoost     Full  0.612745  0.547420  0.179079\n",
      "16     Ridge Classifier  Reduced  0.612745  0.485137  0.222222\n",
      "17             LightGBM  Reduced  0.611111  0.551622  0.173546\n",
      "18     Ridge Classifier     Full  0.609477  0.482594  0.222222\n",
      "19           ExtraTrees  Reduced  0.609477  0.536020  0.174695\n",
      "20             CatBoost     Full  0.607843  0.544560  0.172145\n",
      "21            SVC (rbf)     Full  0.607843  0.494271  0.163098\n",
      "22              XGBoost  Reduced  0.607843  0.551887  0.183785\n",
      "23             CatBoost  Reduced  0.607843  0.546444  0.174180\n",
      "24           ExtraTrees     Full  0.606209  0.542544  0.170231\n",
      "25         RandomForest  Reduced  0.602941  0.536689  0.173990\n",
      "26                  QDA     Full  0.601307  0.566672  0.190948\n",
      "27         RandomForest     Full  0.601307  0.526884  0.170191\n",
      "28              XGBoost     Full  0.596405  0.533669  0.182760\n",
      "29           Perceptron  Reduced  0.588235  0.475986  0.222222\n",
      "30        HistGradBoost  Reduced  0.583333  0.512684  0.180527\n",
      "31           GaussianNB  Reduced  0.580065  0.533084  0.196267\n",
      "32    PassiveAggressive  Reduced  0.575163  0.441751  0.222222\n",
      "33              Bagging     Full  0.575163  0.531023  0.188181\n",
      "34           GaussianNB     Full  0.563725  0.537687  0.210191\n",
      "35            KNN (k=5)  Reduced  0.558824  0.531474  0.199521\n",
      "36              Bagging  Reduced  0.557190  0.515073  0.196362\n",
      "37            KNN (k=5)     Full  0.550654  0.518492  0.204662\n",
      "38                NuSVC     Full  0.550654  0.511230  0.171019\n",
      "39    PassiveAggressive     Full  0.534314  0.410542  0.222222\n",
      "40         DecisionTree     Full  0.524510  0.492620  0.316993\n",
      "41         DecisionTree  Reduced  0.521242  0.486398  0.319172\n",
      "42            ExtraTree  Reduced  0.508170  0.480797  0.327887\n",
      "43            ExtraTree     Full  0.496732  0.461759  0.335512\n",
      "44                NuSVC  Reduced  0.483660  0.485331  0.180835\n",
      "45          BernoulliNB     Full  0.447712  0.344005  0.214250\n",
      "46           Perceptron     Full  0.380719  0.326318  0.222222\n",
      "47          BernoulliNB  Reduced  0.379085  0.200838  0.218746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, PassiveAggressiveClassifier, Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, brier_score_loss\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configurations\n",
    "features_reduced = ['xG', 'xGA', 'strength', 'ppda_coef', 'deep']\n",
    "features_full = ['xG', 'xGA', 'npxG', 'npxGA', 'deep', 'deep_allowed',\n",
    "                 'ppda_coef', 'oppda_coef', 'home', 'strength']\n",
    "\n",
    "X_train_r = train_data[features_reduced].fillna(0)\n",
    "X_test_r  = test_data[features_reduced].fillna(0)\n",
    "\n",
    "X_train_f = train_data[features_full].fillna(0)\n",
    "X_test_f  = test_data[features_full].fillna(0)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_test_bin = lb.fit_transform(y_test)\n",
    "\n",
    "# ==================== Models list ====================\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, multi_class='multinomial'),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"PassiveAggressive\": PassiveAggressiveClassifier(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVC (linear)\": SVC(kernel='linear', probability=True),\n",
    "    \"SVC (rbf)\": SVC(kernel='rbf', probability=True),\n",
    "    \"NuSVC\": NuSVC(probability=True),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"ExtraTree\": ExtraTreeClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"HistGradBoost\": HistGradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "# ==================== Score function ====================\n",
    "def benchmark_models(X_train, X_test, y_train, y_test, config_name=\"\"):\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            try:\n",
    "                y_proba = model.predict_proba(X_test)\n",
    "            except:\n",
    "                y_proba = np.ones((len(y_pred), 3)) / 3\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1  = f1_score(y_test, y_pred, average='macro')\n",
    "            brier = np.mean([\n",
    "                brier_score_loss(y_test_bin[:, i], y_proba[:, i])\n",
    "                for i in range(3)\n",
    "            ])\n",
    "\n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Config': config_name,\n",
    "                'Accuracy': acc,\n",
    "                'F1_macro': f1,\n",
    "                'Brier': brier\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"{name} failed: {e}\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==================== Here modelling is being run ====================\n",
    "df_reduced = benchmark_models(X_train_r, X_test_r, y_train, y_test, config_name='Reduced')\n",
    "df_full    = benchmark_models(X_train_f, X_test_f, y_train, y_test, config_name='Full')\n",
    "\n",
    "df_all = pd.concat([df_reduced, df_full]).sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)\n",
    "print(df_all)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
